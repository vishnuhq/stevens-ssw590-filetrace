# FileTrace CI/CD Pipeline - GitLab CI/CD
# Triggers on push to main branch and merge requests
# MR: Tests + Security only (no secrets needed - uses mocks)
# Merge to main: Full pipeline with deployment

stages:
  - install
  - lint
  - test
  - security
  - build
  - deploy
  - verify

variables:
  AWS_REGION: us-east-1
  ECR_REPOSITORY: filetrace-backend
  NODE_VERSION: '24'
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: ''

# Default rules - can be overridden per job
.rules_mr_and_main:
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

.rules_main_only:
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

# ============================================
# Stage 1: Install Dependencies
# ============================================

install-backend:
  stage: install
  image: node:24  # Full Debian image - required for bcrypt compilation and MongoDB Memory Server
  extends: .rules_mr_and_main
  cache:
    key: backend-${CI_COMMIT_REF_SLUG}
    paths:
      - server/node_modules/
    policy: pull-push
  script:
    - cd server
    - npm ci
  artifacts:
    paths:
      - server/node_modules/
    expire_in: 1 hour

install-frontend:
  stage: install
  image: node:24-alpine
  extends: .rules_mr_and_main
  cache:
    key: frontend-${CI_COMMIT_REF_SLUG}
    paths:
      - client/node_modules/
    policy: pull-push
  script:
    - cd client
    - npm ci
  artifacts:
    paths:
      - client/node_modules/
    expire_in: 1 hour

# ============================================
# Stage 2: Lint Code
# ============================================

lint-backend:
  stage: lint
  image: node:24  # Must match install-backend image (full Debian for bcrypt compatibility)
  extends: .rules_mr_and_main
  dependencies:
    - install-backend
  script:
    - cd server
    - npm run lint --if-present || echo "No lint script found, skipping"

# ============================================
# Stage 3: Run Tests
# Tests use mocked services (no secrets needed)
# ============================================

test-backend:
  stage: test
  image: node:24  # Full Debian - MongoDB Memory Server requires libcurl (not in slim)
  extends: .rules_mr_and_main
  dependencies:
    - install-backend
  variables:
    # CI=true triggers MongoDB Memory Server and mocked S3
    # No real secrets needed - tests are fully isolated
    CI: 'true'
    NODE_ENV: test
  script:
    - cd server
    - npm run test:coverage
  coverage: '/All files[^|]*\|[^|]*\s+([\d\.]+)/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: server/coverage/cobertura-coverage.xml
    paths:
      - server/coverage/
    expire_in: 1 week
    when: always

# ============================================
# Stage 4: Security Scans (no secrets needed)
# ============================================

security-npm-audit:
  stage: security
  image: node:24-alpine
  extends: .rules_mr_and_main
  dependencies:
    - install-backend
  script:
    - cd server
    - npm audit --audit-level=high
  # STRICT: vulnerabilities MUST be fixed

security-trivy-fs:
  stage: security
  image:
    name: aquasec/trivy:latest
    entrypoint: ['']
  extends: .rules_mr_and_main
  script:
    - trivy fs --exit-code 1 --severity HIGH,CRITICAL --no-progress ./server
  # STRICT: exit-code 1 fails on findings

security-trivy-secrets:
  stage: security
  image:
    name: aquasec/trivy:latest
    entrypoint: ['']
  extends: .rules_mr_and_main
  script:
    - trivy fs --scanners secret --exit-code 1 --no-progress ./server
  # STRICT: exit-code 1 fails on secret findings

# ============================================
# Stage 5: Build Docker Image
# ONLY ON MAIN (Requires secrets)
# ============================================

build-docker:
  stage: build
  image: docker:24-dind
  extends: .rules_main_only
  needs:
    - job: test-backend
      artifacts: false
    - job: security-npm-audit
      artifacts: false
    - job: security-trivy-fs
      artifacts: false
    - job: security-trivy-secrets
      artifacts: false
  services:
    - docker:24-dind
  variables:
    DOCKER_HOST: tcp://docker:2375
  before_script:
    - apk add --no-cache aws-cli curl
    # Install Trivy binary directly (NOT as nested docker container)
    # This allows Trivy to use DOCKER_HOST to access DinD daemon
    - curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin
    - trivy --version
    - aws --version
    - |
      aws ecr get-login-password --region $AWS_REGION | \
      docker login --username AWS --password-stdin \
      $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com
  script:
    - echo "Building Docker image..."
    - |
      docker build -t $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPOSITORY:$CI_COMMIT_SHA .
    - |
      docker tag $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPOSITORY:$CI_COMMIT_SHA \
      $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPOSITORY:latest

    - echo "Scanning Docker image with Trivy (STRICT - blocks on HIGH/CRITICAL)..."
    - |
      trivy image --exit-code 1 --severity HIGH,CRITICAL \
      --scanners vuln,secret \
      $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPOSITORY:$CI_COMMIT_SHA
    # Image MUST pass security scan before push
    - echo "Pushing Docker image to ECR..."
    - |
      docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPOSITORY:$CI_COMMIT_SHA
    - |
      docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPOSITORY:latest

# ============================================
# Stage 6: Deploy
# ONLY ON MAIN
# ============================================

deploy-backend:
  stage: deploy
  image: alpine:latest
  extends: .rules_main_only
  needs:
    - job: build-docker
      artifacts: false
  before_script:
    - apk add --no-cache openssh-client aws-cli
    - mkdir -p ~/.ssh
    # EC2_SSH_KEY is a File type variable - contains path, not content
    - cp "$EC2_SSH_KEY" ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - ssh-keyscan -H $EC2_HOST >> ~/.ssh/known_hosts 2>/dev/null
  script:
    - |
      ssh -o StrictHostKeyChecking=no $EC2_USER@$EC2_HOST << ENDSSH
        # Login to ECR
        aws ecr get-login-password --region us-east-1 | \
        docker login --username AWS --password-stdin \
        $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com

        # Stop and remove old container
        docker stop filetrace-backend 2>/dev/null || true
        docker rm filetrace-backend 2>/dev/null || true

        # Pull new image
        docker pull $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/$ECR_REPOSITORY:$CI_COMMIT_SHA

        # Run new container
        docker run -d \
          --name filetrace-backend \
          --restart unless-stopped \
          -p 3001:3001 \
          -e NODE_ENV=production \
          -e PORT=3001 \
          -e MONGODB_URI="$MONGODB_URI" \
          -e DB_NAME=filetrace \
          -e JWT_SECRET="$JWT_SECRET" \
          -e AWS_ACCESS_KEY_ID="$AWS_ACCESS_KEY_ID" \
          -e AWS_SECRET_ACCESS_KEY="$AWS_SECRET_ACCESS_KEY" \
          -e AWS_REGION=us-east-1 \
          -e S3_BUCKET_NAME="$S3_BUCKET_NAME" \
          -e CLIENT_URL="$CLIENT_URL" \
          $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/$ECR_REPOSITORY:$CI_COMMIT_SHA

        # Clean up old images
        docker image prune -af

        # Verify container is running
        sleep 5
        docker ps | grep filetrace-backend
      ENDSSH

deploy-frontend:
  stage: deploy
  image: node:24-alpine
  extends: .rules_main_only
  dependencies:
    - install-frontend
  before_script:
    - apk add --no-cache aws-cli
  script:
    - cd client
    - echo "VITE_API_URL=$API_URL" > .env
    - npm run build
    - aws s3 sync dist/ s3://$S3_FRONTEND_BUCKET --delete
    - |
      if [ -n "$CLOUDFRONT_DISTRIBUTION_ID" ]; then
        aws cloudfront create-invalidation \
          --distribution-id $CLOUDFRONT_DISTRIBUTION_ID \
          --paths "/*" || true
      fi

# ============================================
# Stage 7: Verify Deployment
# ONLY ON MAIN
# ============================================

verify-backend:
  stage: verify
  image: curlimages/curl:latest
  extends: .rules_main_only
  dependencies: []
  script:
    - sleep 30
    - echo "Checking backend health at http://$EC2_HOST:3001/health"
    - |
      response=$(curl -s -o /dev/null -w "%{http_code}" http://$EC2_HOST:3001/health || echo "000")
      if [ "$response" = "200" ]; then
        echo "Backend is healthy (HTTP 200)"
        curl -s http://$EC2_HOST:3001/health | head -c 500
      else
        echo "Backend health check failed with status: $response"
        exit 1
      fi

verify-frontend:
  stage: verify
  image: curlimages/curl:latest
  extends: .rules_main_only
  dependencies: []
  script:
    - FRONTEND_URL="http://$S3_FRONTEND_BUCKET.s3-website-$AWS_REGION.amazonaws.com"
    - echo "Checking frontend at $FRONTEND_URL"
    - |
      response=$(curl -s -o /dev/null -w "%{http_code}" "$FRONTEND_URL" || echo "000")
      if [ "$response" = "200" ] || [ "$response" = "304" ]; then
        echo "Frontend is available (HTTP $response)"
      else
        echo "Frontend check failed with status: $response"
        exit 1
      fi

# ============================================
# Pipeline Summary
# ============================================
#
# MERGE REQUESTS:
#   install -> lint -> test -> security (all run)
#   NO secrets needed - tests use MongoDB Memory Server + mocked S3
#
# PUSH TO MAIN (after MR merge):
#   install -> lint -> test -> security -> build -> deploy -> verify
#   Requires all CI/CD variables configured
#
# Required GitLab CI/CD Variables (Settings > CI/CD > Variables):
#
# AWS_ACCOUNT_ID         - AWS account ID (e.g., 123456789012)
# AWS_ACCESS_KEY_ID      - AWS access key (Masked)
# AWS_SECRET_ACCESS_KEY  - AWS secret key (Masked)
# MONGODB_URI            - MongoDB Atlas connection string (Masked)
# JWT_SECRET             - JWT signing key (Masked)
# S3_BUCKET_NAME         - File storage bucket name
# S3_FRONTEND_BUCKET     - Frontend hosting bucket name
# EC2_HOST               - EC2 public IP address
# EC2_USER               - EC2 username (ubuntu)
# EC2_SSH_KEY            - SSH private key content (File type, Masked)
# CLIENT_URL             - Frontend URL for CORS
# API_URL                - Backend URL for frontend build
# CLOUDFRONT_DISTRIBUTION_ID - Optional CloudFront distribution
#
# Mark sensitive variables as "Masked" and "Protected"
# ============================================
